{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AIE 121 - Machine Learning Final Project\n",
        "\n",
        "## Customer Churn Prediction & Customer Lifetime Value Prediction\n",
        "\n",
        "This project covers:\n",
        "- Data Collection\n",
        "- Data Cleaning (10 steps)\n",
        "- Exploratory Data Analysis\n",
        "- Visualization (8 types)\n",
        "- Model Building (Classification & Regression)\n",
        "- Model Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.13.7' requires the ipykernel package.\n",
            "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Program Files (x86)/Python313-32/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, roc_auc_score, \n",
        "                             roc_curve, mean_absolute_error, mean_squared_error, \n",
        "                             median_absolute_error, r2_score, confusion_matrix, classification_report)\n",
        "import warnings\n",
        "import os\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for better visualizations\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"AIE 121 - Machine Learning Final Project\")\n",
        "print(\"Customer Churn Prediction & Customer Lifetime Value Prediction\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PART 1: UNDERSTANDING THE PURPOSE\n",
        "\n",
        "**Problem Domain:** Customer Churn Prediction & Customer Lifetime Value Prediction\n",
        "\n",
        "**Goal:**\n",
        "1. **Classification Task:** Predict whether a customer will churn (Yes/No)\n",
        "2. **Regression Task:** Predict customer lifetime value (continuous value)\n",
        "\n",
        "This is a critical business problem as:\n",
        "- Customer retention is cheaper than acquisition\n",
        "- Predicting churn helps in proactive customer retention\n",
        "- Customer lifetime value helps in resource allocation and marketing strategies\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PART 2: DATA COLLECTION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dirty dataset\n",
        "df = pd.read_csv('customer_churn_dirty.csv')\n",
        "print(f\"Dataset loaded successfully!\")\n",
        "print(f\"Shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
        "\n",
        "print(\"\\nFirst few rows of the dataset:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Dataset Info:\")\n",
        "df.info()\n",
        "print(\"\\nBasic Statistics:\")\n",
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PART 3: DATA CLEANING (10 Steps)\n",
        "\n",
        "### Step 1: Deal with Missing Values\n",
        "### Step 2: Figure out why data is missing\n",
        "### Step 3: Eliminating extra variables\n",
        "### Step 4: Eliminating duplicates\n",
        "### Step 5: Detect and remove outliers\n",
        "### Step 6: Scaling and Normalization (done during modeling)\n",
        "### Step 7: Eliminating blank spaces\n",
        "### Step 8: Arranging data logically\n",
        "### Step 9: Grouping data\n",
        "### Step 10: Dealing with Inconsistent Data Entry\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1 & 2: Missing Values Analysis\n",
        "print(\"--- Step 1 & 2: Missing Values Analysis ---\")\n",
        "missing_counts = df.isnull().sum()\n",
        "print(\"Missing values per column:\")\n",
        "print(missing_counts[missing_counts > 0])\n",
        "print(\"\\nMissing data percentage:\")\n",
        "missing_percent = (df.isnull().sum() / len(df)) * 100\n",
        "print(missing_percent[missing_percent > 0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Eliminating duplicates\n",
        "print(\"--- Step 4: Removing Duplicates ---\")\n",
        "duplicates_before = df.duplicated().sum()\n",
        "print(f\"Number of duplicate rows: {duplicates_before}\")\n",
        "df = df.drop_duplicates()\n",
        "print(f\"Rows after removing duplicates: {len(df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 5: Detect and remove outliers using IQR method\n",
        "print(\"--- Step 5: Outlier Detection and Removal ---\")\n",
        "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "print(f\"Numerical columns: {numerical_cols}\")\n",
        "\n",
        "# Remove outliers using IQR method\n",
        "for col in numerical_cols:\n",
        "    if col in df.columns:\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "        outliers = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()\n",
        "        print(f\"{col}: {outliers} outliers detected\")\n",
        "        # Remove outliers\n",
        "        df = df[(df[col] >= lower_bound) | (df[col].isna())]\n",
        "        df = df[(df[col] <= upper_bound) | (df[col].isna())]\n",
        "\n",
        "print(f\"Rows after removing outliers: {len(df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 7: Eliminating blank spaces\n",
        "print(\"--- Step 7: Handling Blank Spaces ---\")\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "for col in categorical_cols:\n",
        "    if col in df.columns:\n",
        "        # Replace blank spaces with NaN\n",
        "        df[col] = df[col].replace([' ', ''], np.nan)\n",
        "        # Also handle strings that are just whitespace\n",
        "        df[col] = df[col].apply(lambda x: np.nan if isinstance(x, str) and x.strip() == '' else x)\n",
        "\n",
        "# Use Simple Imputer for missing values\n",
        "print(\"\\n--- Using Simple Imputer for Missing Values ---\")\n",
        "numerical_imputer = SimpleImputer(strategy='median')\n",
        "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Apply imputation\n",
        "for col in numerical_cols:\n",
        "    if col in df.columns and df[col].isnull().sum() > 0:\n",
        "        df[col] = numerical_imputer.fit_transform(df[[col]]).ravel()\n",
        "\n",
        "for col in categorical_cols:\n",
        "    if col in df.columns and df[col].isnull().sum() > 0:\n",
        "        df[col] = categorical_imputer.fit_transform(df[[col]]).ravel()\n",
        "\n",
        "print(\"Missing values after imputation:\", df.isnull().sum().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 8: Arranging data logically\n",
        "df = df.sort_values(by=['tenure_months', 'age']).reset_index(drop=True)\n",
        "\n",
        "# Step 10: Dealing with Inconsistent Data Entry\n",
        "print(\"--- Step 10: Standardizing Categorical Data ---\")\n",
        "for col in categorical_cols:\n",
        "    if col in df.columns:\n",
        "        # Convert to lowercase and standardize\n",
        "        df[col] = df[col].astype(str).str.lower().str.strip()\n",
        "        # Standardize specific values\n",
        "        if 'churn' in col.lower():\n",
        "            df[col] = df[col].replace(['yes', 'y'], 'yes')\n",
        "            df[col] = df[col].replace(['no', 'n'], 'no')\n",
        "        elif 'gender' in col.lower():\n",
        "            df[col] = df[col].replace(['male', 'm'], 'male')\n",
        "            df[col] = df[col].replace(['female', 'f'], 'female')\n",
        "        elif 'yes' in df[col].values or 'no' in df[col].values:\n",
        "            df[col] = df[col].replace(['yes', 'y'], 'yes')\n",
        "            df[col] = df[col].replace(['no', 'n'], 'no')\n",
        "\n",
        "# Remove negative values where they shouldn't exist\n",
        "df['monthly_charges'] = df['monthly_charges'].abs()\n",
        "df['age'] = df['age'].abs()\n",
        "df['total_charges'] = df['total_charges'].abs()\n",
        "\n",
        "print(\"Data cleaning completed!\")\n",
        "print(f\"Final dataset shape: {df.shape}\")\n",
        "print(f\"Final missing values: {df.isnull().sum().sum()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PART 4: EXPLORATORY DATA ANALYSIS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation Analysis\n",
        "numerical_df = df.select_dtypes(include=[np.number])\n",
        "correlation_matrix = numerical_df.corr()\n",
        "print(\"Correlation Matrix:\")\n",
        "print(correlation_matrix)\n",
        "\n",
        "# Visualize correlation matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
        "plt.title('Correlation Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PART 5: VISUALIZATION (8 Types)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create directory for saving plots\n",
        "os.makedirs('visualizations', exist_ok=True)\n",
        "\n",
        "# 1. Line Plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "monthly_charges_by_tenure = df.groupby('tenure_months')['monthly_charges'].mean().sort_index()\n",
        "plt.plot(monthly_charges_by_tenure.index, monthly_charges_by_tenure.values, marker='o', linewidth=2)\n",
        "plt.xlabel('Tenure (Months)')\n",
        "plt.ylabel('Average Monthly Charges')\n",
        "plt.title('Line Plot: Average Monthly Charges by Tenure')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('visualizations/1_line_plot.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Area Plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "churn_by_contract = df.groupby('contract_type')['churn'].value_counts().unstack(fill_value=0)\n",
        "churn_by_contract.plot(kind='area', stacked=True, alpha=0.7)\n",
        "plt.xlabel('Contract Type')\n",
        "plt.ylabel('Number of Customers')\n",
        "plt.title('Area Plot: Churn Distribution by Contract Type')\n",
        "plt.legend(title='Churn')\n",
        "plt.tight_layout()\n",
        "plt.savefig('visualizations/2_area_plot.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Histogram\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.hist(df['age'], bins=30, edgecolor='black', alpha=0.7, color='skyblue')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram: Age Distribution')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('visualizations/3_histogram.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Bar Chart\n",
        "plt.figure(figsize=(12, 6))\n",
        "churn_counts = df['churn'].value_counts()\n",
        "plt.bar(churn_counts.index, churn_counts.values, color=['#ff6b6b', '#4ecdc4'], alpha=0.7)\n",
        "plt.xlabel('Churn')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Bar Chart: Churn Distribution')\n",
        "plt.grid(True, alpha=0.3, axis='y')\n",
        "plt.tight_layout()\n",
        "plt.savefig('visualizations/4_bar_chart.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Pie Chart\n",
        "plt.figure(figsize=(10, 8))\n",
        "contract_counts = df['contract_type'].value_counts()\n",
        "plt.pie(contract_counts.values, labels=contract_counts.index, autopct='%1.1f%%', startangle=90)\n",
        "plt.title('Pie Chart: Contract Type Distribution')\n",
        "plt.tight_layout()\n",
        "plt.savefig('visualizations/5_pie_chart.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Box Plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "df.boxplot(column=['monthly_charges', 'total_charges', 'tenure_months'], grid=True)\n",
        "plt.ylabel('Value')\n",
        "plt.title('Box Plot: Distribution of Numerical Features')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.savefig('visualizations/6_box_plot.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. Scatter Plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "churn_colors = {'yes': 'red', 'no': 'blue'}\n",
        "colors = df['churn'].map(churn_colors)\n",
        "plt.scatter(df['monthly_charges'], df['total_charges'], c=colors, alpha=0.5, s=50)\n",
        "plt.xlabel('Monthly Charges')\n",
        "plt.ylabel('Total Charges')\n",
        "plt.title('Scatter Plot: Monthly Charges vs Total Charges (colored by Churn)')\n",
        "plt.legend(handles=[plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='Churn: Yes'),\n",
        "                    plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markersize=10, label='Churn: No')])\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('visualizations/7_scatter_plot.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. Bubble Plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "churn_yes = df[df['churn'] == 'yes']\n",
        "churn_no = df[df['churn'] == 'no']\n",
        "plt.scatter(churn_yes['age'], churn_yes['monthly_charges'], \n",
        "           s=churn_yes['tenure_months']*5, alpha=0.5, c='red', label='Churn: Yes')\n",
        "plt.scatter(churn_no['age'], churn_no['monthly_charges'], \n",
        "           s=churn_no['tenure_months']*5, alpha=0.5, c='blue', label='Churn: No')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Monthly Charges')\n",
        "plt.title('Bubble Plot: Age vs Monthly Charges (bubble size = tenure)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('visualizations/8_bubble_plot.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PART 6: BUILD MODEL\n",
        "\n",
        "### Step 1: Determine inputs and outputs\n",
        "- **Classification**: Predict Churn (Yes/No)\n",
        "- **Regression**: Predict Customer Lifetime Value\n",
        "\n",
        "### Step 2: Label Encoding for categorical data\n",
        "### Step 3 & 4: Model Selection and Training (4+ models)\n",
        "### Step 5: Model Evaluation\n",
        "### Step 6: Check if scaling affects accuracy\n",
        "### Step 7: Check if normalization affects accuracy\n",
        "### Step 9: Visualize results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for modeling\n",
        "feature_cols = ['age', 'monthly_charges', 'total_charges', 'tenure_months', \n",
        "                'monthly_usage_gb', 'customer_satisfaction', 'number_of_services',\n",
        "                'gender', 'contract_type', 'payment_method', 'internet_service',\n",
        "                'phone_service', 'streaming_tv', 'streaming_movies']\n",
        "\n",
        "X = df[feature_cols].copy()\n",
        "y_classification = df['churn'].copy()\n",
        "y_regression = df['customer_lifetime_value'].copy()\n",
        "\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Classification target shape: {y_classification.shape}\")\n",
        "print(f\"Regression target shape: {y_regression.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Label Encoding for categorical data\n",
        "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "numerical_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "print(f\"Categorical features: {categorical_features}\")\n",
        "print(f\"Numerical features: {numerical_features}\")\n",
        "\n",
        "# Manual encoding\n",
        "label_encoders = {}\n",
        "X_encoded = X.copy()\n",
        "\n",
        "for col in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    X_encoded[col] = le.fit_transform(X[col].astype(str))\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Encode target for classification\n",
        "le_target = LabelEncoder()\n",
        "y_classification_encoded = le_target.fit_transform(y_classification)\n",
        "\n",
        "# Final feature matrix\n",
        "X_final = X_encoded.values\n",
        "print(f\"Final feature matrix shape: {X_final.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train_clf, y_test_clf = train_test_split(\n",
        "    X_final, y_classification_encoded, test_size=0.2, random_state=42, stratify=y_classification_encoded\n",
        ")\n",
        "\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
        "    X_final, y_regression, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Train set size: {X_train.shape[0]}\")\n",
        "print(f\"Test set size: {X_test.shape[0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classification Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Classification Models\n",
        "classification_models = {\n",
        "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
        "    'SVM': SVC(probability=True, random_state=42)\n",
        "}\n",
        "\n",
        "classification_results = {}\n",
        "\n",
        "for name, model in classification_models.items():\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "    model.fit(X_train, y_train_clf)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
        "    \n",
        "    accuracy = accuracy_score(y_test_clf, y_pred)\n",
        "    precision = precision_score(y_test_clf, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test_clf, y_pred, average='weighted')\n",
        "    roc_auc = roc_auc_score(y_test_clf, y_pred_proba) if y_pred_proba is not None else None\n",
        "    \n",
        "    classification_results[name] = {\n",
        "        'model': model,\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'roc_auc': roc_auc,\n",
        "        'y_pred': y_pred,\n",
        "        'y_pred_proba': y_pred_proba\n",
        "    }\n",
        "    \n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    if roc_auc:\n",
        "        print(f\"ROC-AUC: {roc_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Regression Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Regression Models\n",
        "regression_models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
        "    'SVR': SVR()\n",
        "}\n",
        "\n",
        "regression_results = {}\n",
        "\n",
        "for name, model in regression_models.items():\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "    model.fit(X_train_reg, y_train_reg)\n",
        "    y_pred = model.predict(X_test_reg)\n",
        "    \n",
        "    mae = mean_absolute_error(y_test_reg, y_pred)\n",
        "    mse = mean_squared_error(y_test_reg, y_pred)\n",
        "    median_ae = median_absolute_error(y_test_reg, y_pred)\n",
        "    r2 = r2_score(y_test_reg, y_pred)\n",
        "    \n",
        "    regression_results[name] = {\n",
        "        'model': model,\n",
        "        'mae': mae,\n",
        "        'mse': mse,\n",
        "        'median_ae': median_ae,\n",
        "        'r2': r2,\n",
        "        'y_pred': y_pred\n",
        "    }\n",
        "    \n",
        "    print(f\"Mean Absolute Error: {mae:.4f}\")\n",
        "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
        "    print(f\"Median Absolute Error: {median_ae:.4f}\")\n",
        "    print(f\"R² Score: {r2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 6: Testing Effect of Scaling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_train_reg_scaled = scaler.fit_transform(X_train_reg)\n",
        "X_test_reg_scaled = scaler.transform(X_test_reg)\n",
        "\n",
        "print(\"--- Classification with Scaling ---\")\n",
        "scaled_clf_results = {}\n",
        "for name, model in classification_models.items():\n",
        "    model_scaled = type(model)(**model.get_params()) if hasattr(model, 'get_params') else type(model)()\n",
        "    model_scaled.fit(X_train_scaled, y_train_clf)\n",
        "    y_pred = model_scaled.predict(X_test_scaled)\n",
        "    accuracy = accuracy_score(y_test_clf, y_pred)\n",
        "    scaled_clf_results[name] = accuracy\n",
        "    print(f\"{name}: Accuracy = {accuracy:.4f} (Original: {classification_results[name]['accuracy']:.4f})\")\n",
        "\n",
        "print(\"\\n--- Regression with Scaling ---\")\n",
        "scaled_reg_results = {}\n",
        "for name, model in regression_models.items():\n",
        "    model_scaled = type(model)(**model.get_params()) if hasattr(model, 'get_params') else type(model)()\n",
        "    model_scaled.fit(X_train_reg_scaled, y_train_reg)\n",
        "    y_pred = model_scaled.predict(X_test_reg_scaled)\n",
        "    r2 = r2_score(y_test_reg, y_pred)\n",
        "    scaled_reg_results[name] = r2\n",
        "    print(f\"{name}: R² = {r2:.4f} (Original: {regression_results[name]['r2']:.4f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 7: Testing Effect of Normalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalization\n",
        "normalizer = MinMaxScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)\n",
        "X_train_reg_norm = normalizer.fit_transform(X_train_reg)\n",
        "X_test_reg_norm = normalizer.transform(X_test_reg)\n",
        "\n",
        "print(\"--- Classification with Normalization ---\")\n",
        "norm_clf_results = {}\n",
        "for name, model in classification_models.items():\n",
        "    model_norm = type(model)(**model.get_params()) if hasattr(model, 'get_params') else type(model)()\n",
        "    model_norm.fit(X_train_norm, y_train_clf)\n",
        "    y_pred = model_norm.predict(X_test_norm)\n",
        "    accuracy = accuracy_score(y_test_clf, y_pred)\n",
        "    norm_clf_results[name] = accuracy\n",
        "    print(f\"{name}: Accuracy = {accuracy:.4f} (Original: {classification_results[name]['accuracy']:.4f})\")\n",
        "\n",
        "print(\"\\n--- Regression with Normalization ---\")\n",
        "norm_reg_results = {}\n",
        "for name, model in regression_models.items():\n",
        "    model_norm = type(model)(**model.get_params()) if hasattr(model, 'get_params') else type(model)()\n",
        "    model_norm.fit(X_train_reg_norm, y_train_reg)\n",
        "    y_pred = model_norm.predict(X_test_reg_norm)\n",
        "    r2 = r2_score(y_test_reg, y_pred)\n",
        "    norm_reg_results[name] = r2\n",
        "    print(f\"{name}: R² = {r2:.4f} (Original: {regression_results[name]['r2']:.4f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 9: Visualize Model Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Classification Results Visualization\n",
        "plt.figure(figsize=(14, 10))\n",
        "\n",
        "# 1. Classification Metrics Comparison\n",
        "plt.subplot(2, 2, 1)\n",
        "models = list(classification_results.keys())\n",
        "accuracies = [classification_results[m]['accuracy'] for m in models]\n",
        "precisions = [classification_results[m]['precision'] for m in models]\n",
        "recalls = [classification_results[m]['recall'] for m in models]\n",
        "\n",
        "x = np.arange(len(models))\n",
        "width = 0.25\n",
        "plt.bar(x - width, accuracies, width, label='Accuracy', alpha=0.8)\n",
        "plt.bar(x, precisions, width, label='Precision', alpha=0.8)\n",
        "plt.bar(x + width, recalls, width, label='Recall', alpha=0.8)\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Classification Metrics Comparison')\n",
        "plt.xticks(x, models, rotation=45, ha='right')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 2. ROC Curve\n",
        "plt.subplot(2, 2, 2)\n",
        "for name, results in classification_results.items():\n",
        "    if results['y_pred_proba'] is not None:\n",
        "        fpr, tpr, _ = roc_curve(y_test_clf, results['y_pred_proba'])\n",
        "        plt.plot(fpr, tpr, label=f\"{name} (AUC={results['roc_auc']:.3f})\")\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Regression Metrics Comparison\n",
        "plt.subplot(2, 2, 3)\n",
        "reg_models = list(regression_results.keys())\n",
        "r2_scores = [regression_results[m]['r2'] for m in reg_models]\n",
        "mae_scores = [regression_results[m]['mae'] for m in reg_models]\n",
        "mae_normalized = [m / max(mae_scores) for m in mae_scores]\n",
        "\n",
        "x = np.arange(len(reg_models))\n",
        "width = 0.35\n",
        "plt.bar(x - width/2, r2_scores, width, label='R² Score', alpha=0.8)\n",
        "plt.bar(x + width/2, mae_normalized, width, label='MAE (normalized)', alpha=0.8)\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Regression Metrics Comparison')\n",
        "plt.xticks(x, reg_models, rotation=45, ha='right')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 4. Actual vs Predicted\n",
        "plt.subplot(2, 2, 4)\n",
        "best_reg_model = max(regression_results.items(), key=lambda x: x[1]['r2'])\n",
        "best_name = best_reg_model[0]\n",
        "best_pred = best_reg_model[1]['y_pred']\n",
        "plt.scatter(y_test_reg, best_pred, alpha=0.5)\n",
        "plt.plot([y_test_reg.min(), y_test_reg.max()], [y_test_reg.min(), y_test_reg.max()], 'r--', lw=2)\n",
        "plt.xlabel('Actual Customer Lifetime Value')\n",
        "plt.ylabel('Predicted Customer Lifetime Value')\n",
        "plt.title(f'Actual vs Predicted ({best_name})')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('visualizations/model_results.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion Matrix for Best Classification Model\n",
        "best_clf_model = max(classification_results.items(), key=lambda x: x[1]['accuracy'])\n",
        "best_clf_name = best_clf_model[0]\n",
        "best_clf_pred = best_clf_model[1]['y_pred']\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "cm = confusion_matrix(y_test_clf, best_clf_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=['No Churn', 'Churn'], \n",
        "            yticklabels=['No Churn', 'Churn'])\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.title(f'Confusion Matrix - {best_clf_name}')\n",
        "plt.tight_layout()\n",
        "plt.savefig('visualizations/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nBest Classification Model: {best_clf_name}\")\n",
        "print(f\"Best Regression Model: {best_reg_model[0]}\")\n",
        "print(\"\\nProject completed successfully!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
